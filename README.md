# REAL-TIME-DISTILLATION-COLUMN-CONTROL-USING-DEEP-REINFORCEMENT-LEARNING

Distillation columns are foundational to chemical engineering, serving as critical units in industries such as petrochemicals, pharmaceuticals, and food processing. These systems separate liquid mixtures into their constituent components by leveraging differences in volatility, requiring precise control to maintain product purity, ensure operational safety, and optimize energy efficiency. The control of a distillation column is inherently complex due to its nonlinear dynamics, multivariable interactions, and susceptibility to disturbances such as variations in feed composition, flow rate, or temperature. Traditional control strategies, such as Proportional-Integral-Derivative (PID) controllers, are widely used for their simplicity and reliability in well-characterized, stable operating conditions. However, these methods often struggle to adapt to abrupt changes or maintain optimal performance across a wide range of dynamic scenarios, leading to suboptimal product quality or excessive energy consumption.To address these challenges, this project explores the application of reinforcement learning (RL) to develop an adaptive control strategy for real-time management of a distillation column. RL offers a framework where a control agent learns an effective policy through iterative interaction with the system, guided by a reward signal that quantifies performance objectives. 

Unlike traditional controllers, which rely on predefined models or fixed tuning parameters, RL enables the agent to adapt to changing conditions by directly learning from process data. This project focuses on controlling the reflux ratioâ€”a critical operational parameter that governs the balance between product purity and energy usage. By adjusting the reflux ratio in response to real-time process conditions, the goal is to achieve a robust control strategy that maintains high product quality while minimizing energy costs, even under unpredictable disturbances.The motivation for this work stems from the growing need for advanced control methods in industrial processes, where efficiency and sustainability are paramount. Distillation columns account for a significant portion of energy consumption in chemical plants, with estimates suggesting they consume over 40% of the energy in refining processes. Improving control strategies can lead to substantial economic and environmental benefits, reducing operational costs and carbon footprints. 

By applying RL, this project aims to bridge the gap between traditional control engineering and modern computational methods, offering a proof-of-concept for a flexible, adaptive approach to process control. The methodology builds on a comprehensive dataset of process variables, modeling the distillation column as a Markov Decision Process (MDP) to enable systematic learning and evaluation. This work not only demonstrates the potential of RL in a complex industrial context but also establishes a foundation for future research into scalable, robust control systems for chemical engineering applications.


